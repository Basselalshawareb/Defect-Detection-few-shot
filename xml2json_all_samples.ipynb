{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'datasets/NEU_DET/all_instances'\n",
    "output_jsonpath = \"datasets/NEU_DET/all_samples.json\"\n",
    "xml_list =[os.path.join(f\"{path}/{xml_file_path}\") for xml_file_path in os.listdir(path)]\n",
    "\n",
    "label_path = 'datasets/NEU_DET/all_instances/label_path.txt'\n",
    "with open(label_path,'w') as f:\n",
    "    for xml_path in xml_list:\n",
    "           f.write(xml_path)\n",
    "           f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['crazing','inclusion','patches','pitted_surface','rolled-in_scale','scratches']\n",
    "cats_path = 'datasets/NEU_DET/all_instances/labels.txt'\n",
    "with open(cats_path,'w') as f:\n",
    "    for label in labels:\n",
    "       f.write(label)\n",
    "       f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "\n",
    "def get_label2id(labels_path: str) -> Dict[str, int]:\n",
    "    \"\"\"id is 1 start\"\"\"\n",
    "    with open(labels_path, 'r') as f:\n",
    "        labels_str = f.read().split()\n",
    "    labels_ids = list(range(1, len(labels_str)+1))\n",
    "    return dict(zip(labels_str, labels_ids))\n",
    "\n",
    "\n",
    "def get_annpaths(ann_dir_path: str = None,\n",
    "                 ann_ids_path: str = None,\n",
    "                 ext: str = '',\n",
    "                 annpaths_list_path: str = None) -> List[str]:\n",
    "    # If use annotation paths list\n",
    "    if annpaths_list_path is not None:\n",
    "        with open(annpaths_list_path, 'r') as f:\n",
    "            ann_paths = f.read().split()\n",
    "        return ann_paths\n",
    "\n",
    "    # If use annotaion ids list\n",
    "    ext_with_dot = '.' + ext if ext != '' else ''\n",
    "    with open(ann_ids_path, 'r') as f:\n",
    "        ann_ids = f.read().split()\n",
    "    ann_paths = [os.path.join(ann_dir_path, aid+ext_with_dot) for aid in ann_ids]\n",
    "    return ann_paths\n",
    "\n",
    "\n",
    "def get_image_info(annotation_root, extract_num_from_imgid=True):\n",
    "    path = annotation_root.findtext('path')\n",
    "    if path is None:\n",
    "        filename = annotation_root.findtext('filename')\n",
    "    else:\n",
    "        filename = os.path.basename(path)\n",
    "    img_name = os.path.basename(filename)\n",
    "    img_id = os.path.splitext(img_name)[0]\n",
    "    if extract_num_from_imgid and isinstance(img_id, str):\n",
    "        if img_id[:2] == 'cr':\n",
    "            img_id = int(re.findall(r'\\d+', img_id)[0]+'1111')\n",
    "        elif img_id[:2] == 'in':\n",
    "            img_id = int(re.findall(r'\\d+', img_id)[0]+'2222')\n",
    "        elif img_id[:2] == 'pa':\n",
    "            img_id = int(re.findall(r'\\d+', img_id)[0]+'3333')\n",
    "        elif img_id[:2] == 'pi':\n",
    "            img_id = int(re.findall(r'\\d+', img_id)[0]+'4444')\n",
    "        elif img_id[:2] == 'ro':\n",
    "            img_id = int(re.findall(r'\\d+', img_id)[0]+'5555')\n",
    "        elif img_id[:2] == 'sc':\n",
    "            img_id = int(re.findall(r'\\d+', img_id)[0]+'6666')\n",
    "\n",
    "    size = annotation_root.find('size')\n",
    "    width = int(size.findtext('width'))\n",
    "    height = int(size.findtext('height'))\n",
    "\n",
    "    image_info = {\n",
    "        'file_name': filename,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'id': img_id\n",
    "    }\n",
    "    return image_info\n",
    "\n",
    "\n",
    "def get_coco_annotation_from_obj(obj, label2id):\n",
    "    label = obj.findtext('name')\n",
    "    assert label in label2id, f\"Error: {label} is not in label2id !\"\n",
    "    category_id = label2id[label]\n",
    "    bndbox = obj.find('bndbox')\n",
    "    xmin = int(bndbox.findtext('xmin')) - 1\n",
    "    ymin = int(bndbox.findtext('ymin')) - 1\n",
    "    xmax = int(bndbox.findtext('xmax'))\n",
    "    ymax = int(bndbox.findtext('ymax'))\n",
    "    assert xmax > xmin and ymax > ymin, f\"Box size error !: (xmin, ymin, xmax, ymax): {xmin, ymin, xmax, ymax}\"\n",
    "    o_width = xmax - xmin\n",
    "    o_height = ymax - ymin\n",
    "    ann = {\n",
    "        'area': o_width * o_height,\n",
    "        'iscrowd': 0,\n",
    "        'bbox': [xmin, ymin, o_width, o_height],\n",
    "        'category_id': category_id,\n",
    "        'ignore': 0,\n",
    "        'segmentation': []  # This script is not for segmentation\n",
    "    }\n",
    "    return ann\n",
    "\n",
    "\n",
    "def convert_xmls_to_cocojson(annotation_paths: List[str],\n",
    "                             label2id: Dict[str, int],\n",
    "                             output_jsonpath: str,\n",
    "                             extract_num_from_imgid: bool = True):\n",
    "    output_json_dict = {\n",
    "        \"images\": [],\n",
    "        \"type\": \"instances\",\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "    bnd_id = 1  # START_BOUNDING_BOX_ID, TODO input as args ?\n",
    "    print('Start converting !')\n",
    "    for a_path in tqdm(annotation_paths):\n",
    "        # Read annotation xml\n",
    "        ann_tree = ET.parse(a_path)\n",
    "        ann_root = ann_tree.getroot()\n",
    "\n",
    "        img_info = get_image_info(annotation_root=ann_root,\n",
    "                                  extract_num_from_imgid=extract_num_from_imgid)\n",
    "        img_id = img_info['id']\n",
    "        output_json_dict['images'].append(img_info)\n",
    "\n",
    "        for obj in ann_root.findall('object'):\n",
    "            ann = get_coco_annotation_from_obj(obj=obj, label2id=label2id)\n",
    "            ann.update({'image_id': img_id, 'id': bnd_id})\n",
    "            output_json_dict['annotations'].append(ann)\n",
    "            bnd_id = bnd_id + 1\n",
    "\n",
    "    for label, label_id in label2id.items():\n",
    "        category_info = {'supercategory': 'none', 'id': label_id, 'name': label}\n",
    "        output_json_dict['categories'].append(category_info)\n",
    "\n",
    "    with open(output_jsonpath, 'w') as f:\n",
    "        output_json = json.dumps(output_json_dict)\n",
    "        f.write(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start converting !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:00<00:00, 12980.93it/s]\n"
     ]
    }
   ],
   "source": [
    "    # convert all xml files to coco json\n",
    "    \n",
    "    labels_path = cats_path\n",
    "    ann_path_list = label_path\n",
    "    \n",
    "    label2id = get_label2id(labels_path=labels_path)\n",
    "    ann_paths = get_annpaths(\n",
    "        ext='xml',\n",
    "        annpaths_list_path=ann_path_list\n",
    "    )\n",
    "    convert_xmls_to_cocojson(\n",
    "        annotation_paths=ann_paths,\n",
    "        label2id=label2id,\n",
    "        output_jsonpath=output_jsonpath,\n",
    "        extract_num_from_imgid=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['area', 'iscrowd', 'bbox', 'category_id', 'ignore', 'segmentation', 'image_id', 'id'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "f = json.load(open('/home/huemorgen/DefectDetection/datasets/NEU_DET/all_samples.json'))\n",
    "f['annotations'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_name', 'height', 'width', 'id'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['images'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8918ddee3d38ef79091271864f3f627777cf8b66327d5b3b9dfd0cdf1bc75853"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('defect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
